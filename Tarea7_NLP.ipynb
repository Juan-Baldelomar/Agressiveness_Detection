{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea7-NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FuRz2HUIxfXn",
        "wv6p23htWKou"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "436dbbc204864347bea4aa0a1e63d208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66a8f85d176849579f8176b1f98cdc8f",
              "IPY_MODEL_1c94d9e4a1504ac997fcb8315b65f1c5",
              "IPY_MODEL_d9bf687caf564afeb3d0b4ac4ccfe163"
            ],
            "layout": "IPY_MODEL_eba7a58cf3d04ef7982ddba426d8fb84"
          }
        },
        "66a8f85d176849579f8176b1f98cdc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c26c044ecb4d6dbd1adbe28de6c530",
            "placeholder": "​",
            "style": "IPY_MODEL_c96e295d78ea497d948ad31c98a9e32f",
            "value": "100%"
          }
        },
        "1c94d9e4a1504ac997fcb8315b65f1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1d406d432044c5bc84f2c9bd1978e9",
            "max": 74,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0192efc9ce3e42ec9d6a81c43df4fb27",
            "value": 74
          }
        },
        "d9bf687caf564afeb3d0b4ac4ccfe163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c96f6447fa4a0a915a4f4011d9ea90",
            "placeholder": "​",
            "style": "IPY_MODEL_0a1308217c1f442a874cfaba52d66cc8",
            "value": " 74/74 [00:00&lt;00:00, 117.43it/s]"
          }
        },
        "eba7a58cf3d04ef7982ddba426d8fb84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c26c044ecb4d6dbd1adbe28de6c530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96e295d78ea497d948ad31c98a9e32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1d406d432044c5bc84f2c9bd1978e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0192efc9ce3e42ec9d6a81c43df4fb27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07c96f6447fa4a0a915a4f4011d9ea90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1308217c1f442a874cfaba52d66cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d483a4f0f84f4ec6a852f699e0e175f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bddd6f440124a378fe88aeb59cab3db",
              "IPY_MODEL_725e3002c47c4d07adf100861704471e",
              "IPY_MODEL_05f329abbcd44947a77170630bb0f2a3"
            ],
            "layout": "IPY_MODEL_1d35a8ef82cc424599735347c5af8cbc"
          }
        },
        "6bddd6f440124a378fe88aeb59cab3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92733292591f4b3fb9087a8fa458cbba",
            "placeholder": "​",
            "style": "IPY_MODEL_3c23ce3d097a46f8a839e619893a582f",
            "value": "Downloading: 100%"
          }
        },
        "725e3002c47c4d07adf100861704471e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b100c53844f74ca4a613b4b8d05cd8fa",
            "max": 323,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_729c6217b10e4d12817e29d5f5747057",
            "value": 323
          }
        },
        "05f329abbcd44947a77170630bb0f2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc24b0b56fe44e05b5b01426f8594ab6",
            "placeholder": "​",
            "style": "IPY_MODEL_601335a01eef4768bf794f18c0c86230",
            "value": " 323/323 [00:00&lt;00:00, 9.86kB/s]"
          }
        },
        "1d35a8ef82cc424599735347c5af8cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92733292591f4b3fb9087a8fa458cbba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c23ce3d097a46f8a839e619893a582f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b100c53844f74ca4a613b4b8d05cd8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729c6217b10e4d12817e29d5f5747057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc24b0b56fe44e05b5b01426f8594ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601335a01eef4768bf794f18c0c86230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cb548ee6aa94febb54babedea5ce2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42e41375efe94031b53a765476cd69d6",
              "IPY_MODEL_f9dd2127e181431889eeabdfe3eea6e6",
              "IPY_MODEL_b1c866d0d803421898fa624931981fd6"
            ],
            "layout": "IPY_MODEL_92f4356d0b62489b9ed792e86b20b595"
          }
        },
        "42e41375efe94031b53a765476cd69d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f46dd64dfa4c0eb64414f742677035",
            "placeholder": "​",
            "style": "IPY_MODEL_2eb178c6f3a0454381a0da2fefb01ffa",
            "value": "Downloading: 100%"
          }
        },
        "f9dd2127e181431889eeabdfe3eea6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d64419ce0745452bbd973037121e59a1",
            "max": 858069,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94ca1171ddbf4c138c184c1f0c2b2415",
            "value": 858069
          }
        },
        "b1c866d0d803421898fa624931981fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f64b74023e4f0c87682764241a4d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d8001cb30f4062a4807d842f300c60",
            "value": " 838k/838k [00:01&lt;00:00, 830kB/s]"
          }
        },
        "92f4356d0b62489b9ed792e86b20b595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f46dd64dfa4c0eb64414f742677035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb178c6f3a0454381a0da2fefb01ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d64419ce0745452bbd973037121e59a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ca1171ddbf4c138c184c1f0c2b2415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4f64b74023e4f0c87682764241a4d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d8001cb30f4062a4807d842f300c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95db6721f53444838715e57f04fdf2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c67e1f315f24455bc6dd67fb0051ac4",
              "IPY_MODEL_0f9fcf690a834a2e846e60ce67aafdd7",
              "IPY_MODEL_2b927b0ca1f14673b72eba3caeb116d2"
            ],
            "layout": "IPY_MODEL_271e831cbd1449aebf29ecb6a6594af4"
          }
        },
        "7c67e1f315f24455bc6dd67fb0051ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7070f0684a44378ab38a20a848b17e1",
            "placeholder": "​",
            "style": "IPY_MODEL_0802b4a1135446d59155ef55935645a9",
            "value": "Downloading: 100%"
          }
        },
        "0f9fcf690a834a2e846e60ce67aafdd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_742fa1b62b9248cc882176bbaa07c905",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_797e9379d9dc4be8953fb0039d7d72d7",
            "value": 150
          }
        },
        "2b927b0ca1f14673b72eba3caeb116d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548c853943514ff0a369528368f01524",
            "placeholder": "​",
            "style": "IPY_MODEL_0c2b9093d0a742d2af892344031429fa",
            "value": " 150/150 [00:00&lt;00:00, 1.73kB/s]"
          }
        },
        "271e831cbd1449aebf29ecb6a6594af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7070f0684a44378ab38a20a848b17e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0802b4a1135446d59155ef55935645a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "742fa1b62b9248cc882176bbaa07c905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "797e9379d9dc4be8953fb0039d7d72d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "548c853943514ff0a369528368f01524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2b9093d0a742d2af892344031429fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juan-Baldelomar/Agressiveness_Detection/blob/main/Tarea7_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ernx7qEzPMD3"
      },
      "source": [
        "# Tarea 7 - Juan Luis Baldelomar Cabrera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSvcwJizvlGZ"
      },
      "source": [
        "# Load Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcL1588Hl9jc",
        "outputId": "d3041e6e-cda4-464b-bbb0-d8606d04bfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8EDB6gex93_"
      },
      "source": [
        "# Librerías y Archivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLRqrmSNEjjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7bd47b-5848-4bad-b83d-cd623b9ba209"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from tqdm.auto import tqdm\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "\n",
        "# Tools\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from argparse import Namespace\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Callable, Tuple\n",
        "\n",
        "# Preprocessing\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# word embeddings\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
        "\n",
        "# Import pre trained data \n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1111\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "NSL7S18MufTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwZLUAFtVwkD"
      },
      "source": [
        "<h2>  Load Data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHEVseAQ19AL"
      },
      "source": [
        "X_train = pd.read_csv('data/mex20_train.txt', sep='\\r\\n', engine='python', header=None).loc[:,0]\n",
        "y_train = pd.read_csv('data/mex20_train_labels.txt', header=None).loc[:,0]\n",
        "X_val   = pd.read_csv('data/mex20_val.txt', sep='\\r\\n', engine='python', header=None).loc[:,0]\n",
        "y_val   = pd.read_csv('data/mex20_val_labels.txt', header=None).loc[:,0]\n",
        "X_test = pd.read_csv('data/mex20_test_full.txt', sep='\\r\\n', engine='python', header=None).loc[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBmg4yZsKxHM"
      },
      "source": [
        "# Load Vocabulary and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7N9_7yQ5gt5"
      },
      "source": [
        "def get_vocab(corpus: pd.DataFrame,\n",
        "              tokenizer: Callable[[str], list],\n",
        "              max_features: int) -> set:\n",
        "    freq_dist = FreqDist([w.lower() for sentence in corpus\\\n",
        "                                    for w in tokenizer(sentence)])\n",
        "    \n",
        "    sorted_words = sortFreqDict(freq_dist)[:min(max_features-1, len(freq_dist))]\n",
        "    w2idx = {word: i+2 for i, word in enumerate(sorted_words)}\n",
        "\n",
        "    # Append <pad> token with 0 index\n",
        "    sorted_words.append('<pad>')\n",
        "    sorted_words.append('<unk>')\n",
        "    w2idx['<pad>'] = 0\n",
        "    w2idx['<unk>'] = 1\n",
        "\n",
        "    return set(sorted_words), w2idx\n",
        "        \n",
        "def sortFreqDict(freq_dist: FreqDist) -> list:\n",
        "    freq_dict = dict(freq_dist)\n",
        "    return sorted(freq_dict, key=freq_dict.get, reverse=True)\n",
        "\n",
        "tk = TweetTokenizer()\n",
        "vocab, w2idx = get_vocab(X_train, tk.tokenize, 10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings_matrix(vocab, w2idx, word2vec):\n",
        "  embeddings_matrix = np.empty([len(vocab), word2vec.vector_size])\n",
        "  for word in vocab:\n",
        "      if word in word2vec:\n",
        "          embeddings_matrix[w2idx[word]] = word2vec[word]\n",
        "      else:\n",
        "          embeddings_matrix[w2idx[word]] = np.random.rand(word2vec.vector_size)\n",
        "  \n",
        "  embeddings_matrix[w2idx['<unk>']] = np.mean(embeddings_matrix[2:], axis=0)\n",
        "  embeddings_matrix[w2idx['<pad>']] = np.zeros(word2vec.vector_size)\n",
        "  return embeddings_matrix\n",
        "\n",
        "word2vec_data = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Colab_Notebooks/NLP/word2vec_col.txt')"
      ],
      "metadata": {
        "id": "LhU2fBSoTr41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_matrix = get_embeddings_matrix(vocab, w2idx, word2vec_data)"
      ],
      "metadata": {
        "id": "RzWsZAJl81LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "xXiUBbFSVKxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tra = pd.read_csv('data/extra.txt', sep='\\r\\n', engine='python', header=None).loc[:,0]\n",
        "y_tra = pd.read_csv('data/extra_lab.txt', header=None).loc[:,0]"
      ],
      "metadata": {
        "id": "gGV4PvNUjucN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_tra.tolist() + X_train.tolist()\n",
        "y_train = y_tra.tolist() + y_train.tolist()\n",
        "\n",
        "#X_train = X_train.tolist()\n",
        "#y_train = y_train.tolist()"
      ],
      "metadata": {
        "id": "XysNXdylj8PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq18LHJTPC9I"
      },
      "source": [
        "# Dataset Class\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNeKrdaWR_Sz"
      },
      "source": [
        "class aggr_dataset(Dataset):\n",
        "    def __init__(self, data, labels, vocab, w2id, emb_matrix, tk):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.emb_matrix = emb_matrix\n",
        "        self.tk = tk\n",
        "        self.w2id = w2id\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Método principal para cargar una observación del dataset.\n",
        "           label: categoría a la que pertenece la observación.\n",
        "           word_ids: lista de índices de las palbras en el vocabulario.\n",
        "        '''\n",
        "        label = self.labels[index] if self.labels is not None else -1\n",
        "        words, word_ids = self.preprocessed_text(index)\n",
        "        return word_ids, label, words\n",
        "        \n",
        "    def preprocessed_text(self, index):\n",
        "        '''Preprocess text and '''\n",
        "\n",
        "        # remove links, usernames and lower the text\n",
        "        text = self.data[index]\n",
        "        #text = re.sub(r\"http\\S+\", \"http\", text)\n",
        "        #text = re.sub(r\"@([a-z]|[A-Z]|[0-9]|_)+\", \"@usuario\", text)\n",
        "        text = text.lower()\n",
        "        words = self.tk.tokenize(text)\n",
        "        word_ids = [self.w2id[word] if word in self.vocab else 1 for word in words]\n",
        "        return words, word_ids\n",
        "\n",
        "    def get_weights(self):\n",
        "        '''Devuelve pesos inversos para cada categoría. Mayor peso para la categoría con menos observaciones.'''\n",
        "        cat_1 = 0\n",
        "        for l in self.labels:\n",
        "          cat_1 += l\n",
        "\n",
        "        cat_0 = len(self.labels) - cat_1\n",
        "        maxi = max(cat_0, cat_1)\n",
        "        return torch.tensor([maxi/cat_0, maxi/cat_1])\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        '''Función que ejecuta el dataloader para formar batches de datos.'''\n",
        "        zipped_batch = list(zip(*batch))\n",
        "        word_ids = [torch.tensor(t) for t in zipped_batch[0]]\n",
        "        word_ids = torch.cat(word_ids, dim=0)\n",
        "        lengths = torch.tensor([len(t) for t in zipped_batch[0]])\n",
        "        labels = torch.tensor(zipped_batch[1])\n",
        "        words = zipped_batch[2]\n",
        "        return word_ids, lengths, labels, words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = aggr_dataset(X_train, y_train, vocab, w2idx, embeddings_matrix, tk)\n",
        "val_dataset = aggr_dataset(X_val, y_val, vocab, w2idx, embeddings_matrix, tk)\n",
        "test_dataset = aggr_dataset(X_test, None, vocab, w2idx, embeddings_matrix, tk)"
      ],
      "metadata": {
        "id": "V4XUyU0ynPZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, dataloader, criterion, device, use_acc=False, all_labels = None):\n",
        "    '''Función para evaluar el modelo.'''\n",
        "    accumulator = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        losses = []\n",
        "        preds = torch.empty(0).long()\n",
        "        targets = torch.empty(0).long()\n",
        "        scores_list = []\n",
        "        words_list = []\n",
        "        pred_list = []\n",
        "\n",
        "        for data in tqdm(dataloader):\n",
        "            torch.cuda.empty_cache()\n",
        "            seq, seq_len, labels, words = data\n",
        "            seq, labels = seq.to(device), labels.to(device)\n",
        "            output, scores = model(seq, seq_len)\n",
        "            output = F.log_softmax(output, dim=1)\n",
        "            loss = criterion(output, labels)\n",
        "            losses.append(loss.item())\n",
        "            predictions = F.log_softmax(output, dim=1).argmax(1)\n",
        "\n",
        "            preds = torch.cat([preds, predictions.cpu()], dim=0)\n",
        "            targets = torch.cat([targets, labels.cpu()], dim=0)\n",
        "\n",
        "            if scores is not None:\n",
        "                pred_list += predictions.tolist()\n",
        "                scores = scores.cpu().squeeze(2).tolist()\n",
        "                scores_list += scores\n",
        "                words_list += words\n",
        "\n",
        "        model.train()\n",
        "        preds = preds.numpy()\n",
        "        targets = targets.numpy()\n",
        "        metric = accuracy_score(targets, preds) if use_acc else f1_score(targets, preds, average='binary')\n",
        "\n",
        "        return np.mean(losses), metric, scores_list, words_list, pred_list"
      ],
      "metadata": {
        "id": "6L3EVA_KqNmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "EdM2dzSkNxYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_predictions(preds):\n",
        "  print('Id,Expected')\n",
        "  for i, p in enumerate(preds):\n",
        "    print(i, end='')\n",
        "    print(',', end='')\n",
        "    print(p)"
      ],
      "metadata": {
        "id": "cV4bqWLbNwdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JqnhO50RjKN"
      },
      "source": [
        "# GRU con atención"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orWRX0BoYzmg"
      },
      "source": [
        "class AttnModule(nn.Module):\n",
        "    def __init__(self, input_size, attn_hidden_size=128):\n",
        "        '''\n",
        "        input:\n",
        "            input_size: tamaño de la capa oculta de la GRU.\n",
        "            attn_hidden_size: tamaño de la capa oculta.\n",
        "        '''\n",
        "        super(AttnModule, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, attn_hidden_size)\n",
        "        self.fc2 = nn.Linear(attn_hidden_size, 1, bias=False)\n",
        "        \n",
        "    def forward(self, seq, lengths):\n",
        "        '''\n",
        "        input:\n",
        "            seq: secuencia de vectores ocultos de la GRU.\n",
        "            lengths: número de palabras en cada observación.\n",
        "        '''\n",
        "        # unpack hidden states from the GRU\n",
        "        x = pad_packed_sequence(seq)[0]\n",
        "        seq_len, batch_size, nhid = x.size()\n",
        "\n",
        "        # linearize the access to all the hidden states of each batch and compute  their output with tanh as activation function\n",
        "        u = self.fc1(x.view(batch_size*seq_len, nhid))\n",
        "        u = torch.tanh(u)\n",
        "\n",
        "        # u^t * h_i (dot product with the u query vector) to get the score\n",
        "        scores = self.fc2(u)\n",
        "\n",
        "        # get back the scores into their original shape before being linearized in the output calculation\n",
        "        scores = scores.view(seq_len, batch_size, 1)\n",
        "\n",
        "        \n",
        "        # Assign -100 to positions with padding to avoid them being considered through the softmax function.\n",
        "        # this is also needed due to the way output is computed with fc1 and the bias of this layer could modify the padding values \n",
        "        # NOTE: remember that pack_padded_sequence and pad_packed_sequence are inverse operations\n",
        "        scores = nn.utils.rnn.pack_padded_sequence(scores, lengths=lengths,enforce_sorted=False)\n",
        "        scores = nn.utils.rnn.pad_packed_sequence(scores, padding_value=-100)[0]\n",
        "        \n",
        "        # softmaxt to the scores in dim = 0 because the Batch is in dim = 1, and the sequence is along dim = 0\n",
        "        scores = F.softmax(scores, dim=0)\n",
        "\n",
        "        # transpose scores and X to put Batch Dimension first. \n",
        "        # Then transpose dimension 1 and 2 of x to have hidden states from the GRU in columns instead of rows\n",
        "        scores = scores.transpose(0,1)\n",
        "        x = x.transpose(0,1).transpose(1,2)\n",
        "\n",
        "        # for each batch multiply the hidden states by their scores and sum them (a matrix multiplication x * scores does this)\n",
        "        x = torch.bmm(x, scores)\n",
        "        return x.squeeze(2), scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jAF4URJY0-f"
      },
      "source": [
        "class AttnRNN(nn.Module):\n",
        "    def __init__(self, input_size=100, hidden_size=128, num_layers=1,\n",
        "                 bidirectional=False, emb_mat=None, dense_hidden_size=256,\n",
        "                 attn_hidden_size=128, freeze_emb=False):\n",
        "        super(AttnRNN, self).__init__()\n",
        "        self.embeddings = nn.Embedding.from_pretrained(\\\n",
        "                            torch.FloatTensor(emb_mat), freeze=freeze_emb)\n",
        "        self.gru = nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
        "                          num_layers=num_layers, bidirectional=bidirectional)\n",
        "        directions = 2 if bidirectional else 1\n",
        "        self.attn = AttnModule(hidden_size*directions, attn_hidden_size)\n",
        "        self.classifier = nn.Sequential(\\\n",
        "                            nn.Linear(hidden_size*directions, dense_hidden_size),\n",
        "                            nn.BatchNorm1d(dense_hidden_size),\n",
        "                            nn.ReLU(),\n",
        "                            #nn.Linear(dense_hidden_size, dense_hidden_size//2),\n",
        "                            #nn.Dropout(0.3),\n",
        "                            nn.Linear(dense_hidden_size, 2))\n",
        "        \n",
        "    def forward(self, input_seq, lengths):\n",
        "        x = self.embeddings(input_seq)\n",
        "        x = x.split(lengths.tolist())\n",
        "        x = pad_sequence(x)\n",
        "        x = pack_padded_sequence(x, lengths, enforce_sorted=False)\n",
        "        output, hn = self.gru(x)\n",
        "        x, scores = self.attn(output, lengths)\n",
        "        x = self.classifier(x)\n",
        "        return x, scores.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS_hSoG46WNH"
      },
      "source": [
        "**Construimos el Modelo y el Optimizador a Utilizar**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn = train_dataset.collate_fn, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn = val_dataset.collate_fn, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn = test_dataset.collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "zY6X0x0morGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKZZibqcY6eX"
      },
      "source": [
        "lr = 0.0001\n",
        "epochs = 20\n",
        "device = torch.device('cuda')\n",
        "weight_decay=0.0001\n",
        "beta1=0\n",
        "beta2=0.999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best model in drive is a GRU with n_lays = 2, attn_h_s, hidden_s, dense_hidden_s = 128, 128, 256. \n",
        "# bidirectional = TRUE\n",
        "\n",
        "# best model in drive is a LSTM with n_lays = 2, attn_h_s, hidden_s, dense_hidden_s = 128, 128, 256. \n",
        "# bidirectional = TRUE"
      ],
      "metadata": {
        "id": "TspQskX43K5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CweL5I8gY7G_"
      },
      "source": [
        "#model = AttnRNN(emb_mat=train_dataset.emb_matrix, bidirectional=True).to(device)\n",
        "attn_h_s, hidden_s, dense_hidden_s = 128, 128, 256\n",
        "n_lays = 1\n",
        "parameters = {'attn_hidden_size':attn_h_s, 'hidden_size': hidden_s, 'dense_hidden_size': dense_hidden_s, 'layers': n_lays}\n",
        "model = AttnRNN(emb_mat=train_dataset.emb_matrix, \n",
        "                bidirectional=True, \n",
        "                num_layers=n_lays, \n",
        "                attn_hidden_size=attn_h_s, \n",
        "                hidden_size=hidden_s, \n",
        "                dense_hidden_size=dense_hidden_s\n",
        "                ).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay, betas = (beta1, beta2))\n",
        "weight = train_dataset.get_weights().to(device)\n",
        "criterion = nn.NLLLoss(weight = weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAspflNABvJ1"
      },
      "source": [
        "**Cargamos el Modelo del archivo correspondiente de pesos descargado al inicio** (Omitir este paso si se desea entrenar desde 0) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVBvSaB06cLH"
      },
      "source": [
        "**Entrenamos el Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "wZQegVvaY-Dc",
        "outputId": "07e82b0b-57b3-40b1-f708-efe3b7926873"
      },
      "source": [
        "best_val_f1 = 0\n",
        "for epoch in range(epochs):\n",
        "    for data in tqdm(train_dataloader):\n",
        "        torch.cuda.empty_cache()\n",
        "        optimizer.zero_grad()\n",
        "        seq, seq_len, labels, _ = data\n",
        "        seq, labels = seq.to(device), labels.to(device)\n",
        "        output, _ = model(seq, seq_len)\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    model.eval()\n",
        "    train_loss, train_f1, _, _, _ = eval_model(model, train_dataloader, criterion, device, use_acc=True)\n",
        "    val_loss, val_f1, _, _, _ = eval_model(model, val_dataloader, criterion, device, use_acc=True)\n",
        "    model.train()\n",
        "    print('epoch: %d'%(epoch))\n",
        "    print('train_loss: %5f | val_loss: %5f | train_acc: %5f | val_acc: %5f'%(train_loss, val_loss, train_f1, val_f1)) \n",
        "    if val_f1>best_val_f1:\n",
        "        best_val_f1=val_f1\n",
        "        best_state_dict=copy.deepcopy(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0e9b5e65f4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_val_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ28tajVb4je"
      },
      "source": [
        "**DESCOMENTAR SOLO SI DESEA GUARDAR LOS PESOS EN EL DRIVE MONTADO**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(best_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b80vU083KNu",
        "outputId": "7fff5399-4038-44ca-d655-c8808bdc29e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "val_loss, val_f1, _, _, _ = eval_model(model, val_dataloader, criterion, device, use_acc=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "436dbbc204864347bea4aa0a1e63d208",
            "66a8f85d176849579f8176b1f98cdc8f",
            "1c94d9e4a1504ac997fcb8315b65f1c5",
            "d9bf687caf564afeb3d0b4ac4ccfe163",
            "eba7a58cf3d04ef7982ddba426d8fb84",
            "c5c26c044ecb4d6dbd1adbe28de6c530",
            "c96e295d78ea497d948ad31c98a9e32f",
            "5a1d406d432044c5bc84f2c9bd1978e9",
            "0192efc9ce3e42ec9d6a81c43df4fb27",
            "07c96f6447fa4a0a915a4f4011d9ea90",
            "0a1308217c1f442a874cfaba52d66cc8"
          ]
        },
        "id": "qAPLaYCR3R58",
        "outputId": "c1f10c2c-44c6-4232-8a4a-173369e0d3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/74 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "436dbbc204864347bea4aa0a1e63d208"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpX2QanJ3b1W",
        "outputId": "bb07b9fe-6558-4c75-eae7-e9ec752bbcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8739352640545145"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Predictions"
      ],
      "metadata": {
        "id": "js2OfxmgltAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_predictions(test_data, model):\n",
        "  predictions = []\n",
        "  for data in test_data:\n",
        "    seq, seq_len, _, _ = data\n",
        "    seq = seq.to(device)\n",
        "    output, _ = model(seq, seq_len)\n",
        "    preds = F.softmax(output, dim=1)#.argmax(1)\n",
        "    predictions += preds.tolist()\n",
        "  \n",
        "  return predictions"
      ],
      "metadata": {
        "id": "nMw4wPTDvecY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = perform_predictions(test_dataloader, model)\n",
        "preds = np.array(preds)"
      ],
      "metadata": {
        "id": "YIf69id0xL2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_predictions(preds)"
      ],
      "metadata": {
        "id": "Cz7imgGd3qGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a9VpMWv6hI2"
      },
      "source": [
        "**Evaluamos el Modelo** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsYP9eTTZGX_"
      },
      "source": [
        "model.load_state_dict(best_state_dict)\n",
        "train_loss, train_f1, train_scores, train_words, train_pred = eval_model(model, train_dataloader, criterion, device, use_acc=True)\n",
        "val_loss, val_f1, val_scores, val_words, val_pred = eval_model(model, val_dataloader, criterion, device, use_acc=True)\n",
        "test_loss, test_f1, test_scores, test_words, test_pred = eval_model(model, test_dataloader, criterion, device, use_acc=True)\n",
        "print('train_loss: %5f | train_acc: %5f'%(train_loss, train_f1)) \n",
        "print('val_loss: %5f | val_acc: %5f'%(val_loss, val_f1)) \n",
        "print('test_loss: %5f | test_acc: %5f'%(test_loss, test_f1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "82HzgYH8j8LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhff85Dlj9Ys",
        "outputId": "d3ae6914-e4bb-4439-afe4-e23f8c9284c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 33.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 65.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Dataset"
      ],
      "metadata": {
        "id": "qoVn8opBOWjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils.dummy_pt_objects import RobertaForSequenceClassification\n",
        "from transformers import AutoTokenizer, RobertaTokenizer, AutoModelForSequenceClassification, RobertaForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"pysentimiento/robertuito-base-uncased\")\n",
        "#robertuito = AutoModelForSequenceClassification.from_pretrained(\"pysentimiento/robertuito-base-uncased\")\n",
        "#robertuito = robertuito.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "d483a4f0f84f4ec6a852f699e0e175f7",
            "6bddd6f440124a378fe88aeb59cab3db",
            "725e3002c47c4d07adf100861704471e",
            "05f329abbcd44947a77170630bb0f2a3",
            "1d35a8ef82cc424599735347c5af8cbc",
            "92733292591f4b3fb9087a8fa458cbba",
            "3c23ce3d097a46f8a839e619893a582f",
            "b100c53844f74ca4a613b4b8d05cd8fa",
            "729c6217b10e4d12817e29d5f5747057",
            "cc24b0b56fe44e05b5b01426f8594ab6",
            "601335a01eef4768bf794f18c0c86230",
            "5cb548ee6aa94febb54babedea5ce2b9",
            "42e41375efe94031b53a765476cd69d6",
            "f9dd2127e181431889eeabdfe3eea6e6",
            "b1c866d0d803421898fa624931981fd6",
            "92f4356d0b62489b9ed792e86b20b595",
            "e5f46dd64dfa4c0eb64414f742677035",
            "2eb178c6f3a0454381a0da2fefb01ffa",
            "d64419ce0745452bbd973037121e59a1",
            "94ca1171ddbf4c138c184c1f0c2b2415",
            "a4f64b74023e4f0c87682764241a4d1d",
            "f8d8001cb30f4062a4807d842f300c60",
            "95db6721f53444838715e57f04fdf2a6",
            "7c67e1f315f24455bc6dd67fb0051ac4",
            "0f9fcf690a834a2e846e60ce67aafdd7",
            "2b927b0ca1f14673b72eba3caeb116d2",
            "271e831cbd1449aebf29ecb6a6594af4",
            "c7070f0684a44378ab38a20a848b17e1",
            "0802b4a1135446d59155ef55935645a9",
            "742fa1b62b9248cc882176bbaa07c905",
            "797e9379d9dc4be8953fb0039d7d72d7",
            "548c853943514ff0a369528368f01524",
            "0c2b9093d0a742d2af892344031429fa"
          ]
        },
        "id": "79zICiB7kG5X",
        "outputId": "a0bed03b-68ec-4b8a-c3a2-54472a389acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/323 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d483a4f0f84f4ec6a852f699e0e175f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/838k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cb548ee6aa94febb54babedea5ce2b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95db6721f53444838715e57f04fdf2a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    X_train,\n",
        "    #X_train.tolist(),\n",
        "    max_length = 100,\n",
        "    pad_to_max_length=True,\n",
        "    add_special_tokens=True,\n",
        "    truncation = 'longest_first'\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    X_val.tolist(),\n",
        "    max_length = 100,\n",
        "    pad_to_max_length=True,\n",
        "    add_special_tokens=True,\n",
        "    truncation = 'longest_first'\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    X_test.tolist(),\n",
        "    max_length = 100,\n",
        "    pad_to_max_length=True,\n",
        "    add_special_tokens=True,\n",
        "    truncation = 'longest_first'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpr_mcJMkZa3",
        "outputId": "02960610-c307-4fd6-b006-9ebdc67cadb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class aggr_dataset(Dataset):\n",
        "    def __init__(self, data, labels, vocab, w2id, emb_matrix, tk, t_ids, t_masks):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.emb_matrix = emb_matrix\n",
        "        self.tk = tk\n",
        "        self.w2id = w2id\n",
        "        self.t_ids = t_ids\n",
        "        self.t_masks = t_masks\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''Método principal para cargar una observación del dataset.\n",
        "           label: categoría a la que pertenece la observación.\n",
        "           word_ids: lista de índices de las palbras en el vocabulario.\n",
        "        '''\n",
        "        label = self.labels[index] if self.labels is not None else -1\n",
        "        words, word_ids = self.preprocessed_text(index)\n",
        "        return word_ids, label, words, self.t_ids[index], self.t_masks[index]\n",
        "        \n",
        "    def preprocessed_text(self, index):\n",
        "        '''Preprocess text and '''\n",
        "\n",
        "        # remove links, usernames and lower the text\n",
        "        text = self.data[index]\n",
        "        #text = re.sub(r\"http\\S+\", \"http\", text)\n",
        "        #text = re.sub(r\"@([a-z]|[A-Z]|[0-9]|_)+\", \"@usuario\", text)\n",
        "        text = text.lower()\n",
        "        words = self.tk.tokenize(text)\n",
        "        word_ids = [self.w2id[word] if word in self.vocab else 1 for word in words]\n",
        "        return words, word_ids\n",
        "\n",
        "    def get_weights(self):\n",
        "        '''Devuelve pesos inversos para cada categoría. Mayor peso para la categoría con menos observaciones.'''\n",
        "        cat_1 = 0\n",
        "        for l in self.labels:\n",
        "          cat_1 += l\n",
        "\n",
        "        cat_0 = len(self.labels) - cat_1\n",
        "        maxi = max(cat_0, cat_1)\n",
        "        return torch.tensor([maxi/cat_0, maxi/cat_1])\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        '''Función que ejecuta el dataloader para formar batches de datos.'''\n",
        "        zipped_batch = list(zip(*batch))\n",
        "        word_ids = [torch.tensor(t) for t in zipped_batch[0]]\n",
        "        word_ids = torch.cat(word_ids, dim=0)\n",
        "        lengths = torch.tensor([len(t) for t in zipped_batch[0]])\n",
        "        labels = torch.tensor(zipped_batch[1])\n",
        "        words = zipped_batch[2]\n",
        "\n",
        "        t_ids = [v[3] for v in batch]\n",
        "        t_masks = [v[4] for v in batch]\n",
        "        t_ids = torch.stack(t_ids)\n",
        "        t_masks = torch.stack(t_masks)\n",
        "        return word_ids, lengths, labels, words, t_ids, t_masks"
      ],
      "metadata": {
        "id": "1sdSGNf4BB6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(list(map(int, y_train)))\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(list(map(int, y_val.tolist())))\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])"
      ],
      "metadata": {
        "id": "mj5uQKr8kjXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "# class weights\n",
        "#cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_train.tolist()), y=y_train.tolist())\n",
        "cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "# to tensor\n",
        "weights= torch.tensor(cw,dtype=torch.float)\n",
        "# upload to GPU\n",
        "weights = weights.to(device) # to GPU"
      ],
      "metadata": {
        "id": "2BRKVIKOk3CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the loss function\n",
        "cross_entropy = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "T3RidwaBk6pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Robertuito Model"
      ],
      "metadata": {
        "id": "QaOUUZnpK2gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR MODEL Robertuito\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, ConcatDataset\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 8\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_seq, test_mask)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "eusH9GeSkkHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertuitoClasificator(nn.Module):\n",
        "    def __init__(self, transformer):\n",
        "        super(RobertuitoClasificator, self).__init__()\n",
        "        self.transformer = transformer # pretrained\n",
        "        \n",
        "        #self.softmax = nn.LogSoftmax(dim=1) # softmax\n",
        "        #self.clasification = nn.Linear(768,2, bias = True) # clasification layer\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        # Get cls token\n",
        "        x = self.transformer(sent_id, attention_mask=mask, return_dict=False)[0]\n",
        "\n",
        "        # Classification layer\n",
        "        #x = self.clasification(cls)\n",
        "        #x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "SUGWLfXJkwi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pre-trained model and upload to current device\n",
        "model2 = RobertuitoClasificator(robertuito)\n",
        "model2 = model2.to(device)"
      ],
      "metadata": {
        "id": "6vWPi-I2ky12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 2 TEST\n",
        "from transformers import AdamW # optimizer\n",
        "optimizerM2 = AdamW(model2.parameters(), lr = 1e-5, correct_bias=False) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb35o7U1BtdA",
        "outputId": "484525a5-0287-4397-c732-2878c885cf0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train():\n",
        "    \n",
        "    model2.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "  \n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        " \n",
        "        sent_id, mask, labels = batch\n",
        "        \n",
        "        # clear previously calculated gradients \n",
        "        model2.zero_grad()        \n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model2(sent_id, mask)\n",
        "        preds = F.log_softmax(preds, dim=1)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model2.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizerM2.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "TI2sWEfUk9pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "  \n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "        \n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "            # Calculate elapsed time in minutes.\n",
        "            #elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # model predictions\n",
        "            preds = model2(sent_id, mask)\n",
        "            lab = F.log_softmax(preds, dim=1).argmax(1)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "            total_preds.append(preds)\n",
        "        \n",
        "        predictions += lab.cpu().tolist()\n",
        "        targets += labels.cpu().tolist()\n",
        "\n",
        "    \n",
        "    metric = accuracy_score(targets, predictions)\n",
        "    print(metric)\n",
        "    \n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "NARgDd-JlCes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(3):\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    #save the best model\n",
        "    torch.save(model2.state_dict(), 'saved_weights'+str(epoch)+'.pt')\n",
        "    # Results\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H32BCp5xClhc",
        "outputId": "21b096ee-1a3c-4978-f764-ba06c221a0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of    785.\n",
            "  Batch   100  of    785.\n",
            "  Batch   150  of    785.\n",
            "  Batch   200  of    785.\n",
            "  Batch   250  of    785.\n",
            "  Batch   300  of    785.\n",
            "  Batch   350  of    785.\n",
            "  Batch   400  of    785.\n",
            "  Batch   450  of    785.\n",
            "  Batch   500  of    785.\n",
            "  Batch   550  of    785.\n",
            "  Batch   600  of    785.\n",
            "  Batch   650  of    785.\n",
            "  Batch   700  of    785.\n",
            "  Batch   750  of    785.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.9045996592844975\n",
            "\n",
            "Training Loss: 0.374\n",
            "Validation Loss: -1.922\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of    785.\n",
            "  Batch   100  of    785.\n",
            "  Batch   150  of    785.\n",
            "  Batch   200  of    785.\n",
            "  Batch   250  of    785.\n",
            "  Batch   300  of    785.\n",
            "  Batch   350  of    785.\n",
            "  Batch   400  of    785.\n",
            "  Batch   450  of    785.\n",
            "  Batch   500  of    785.\n",
            "  Batch   550  of    785.\n",
            "  Batch   600  of    785.\n",
            "  Batch   650  of    785.\n",
            "  Batch   700  of    785.\n",
            "  Batch   750  of    785.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.9063032367972743\n",
            "\n",
            "Training Loss: 0.168\n",
            "Validation Loss: -2.599\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of    785.\n",
            "  Batch   100  of    785.\n",
            "  Batch   150  of    785.\n",
            "  Batch   200  of    785.\n",
            "  Batch   250  of    785.\n",
            "  Batch   300  of    785.\n",
            "  Batch   350  of    785.\n",
            "  Batch   400  of    785.\n",
            "  Batch   450  of    785.\n",
            "  Batch   500  of    785.\n",
            "  Batch   550  of    785.\n",
            "  Batch   600  of    785.\n",
            "  Batch   650  of    785.\n",
            "  Batch   700  of    785.\n",
            "  Batch   750  of    785.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.8960817717206133\n",
            "\n",
            "Training Loss: 0.067\n",
            "Validation Loss: -3.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.load_state_dict(torch.load('saved_weights2.pt'))\n",
        "model2.eval()\n",
        "evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlGoXdvCi9q3",
        "outputId": "82278e1d-ecc8-4c78-d022-3b074d67b84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.9045996592844975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.475469028224816, array([[ 1.8261124, -1.7547202],\n",
              "        [ 4.868897 , -5.156266 ],\n",
              "        [-4.467583 ,  4.572062 ],\n",
              "        ...,\n",
              "        [ 4.455827 , -5.1700225],\n",
              "        [ 1.7008258, -2.2183805],\n",
              "        [ 4.0854645, -4.737025 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  '/content/saved_weights2.pt' '/content/drive/MyDrive/Colab_Notebooks/NLP/solo_robertuito.pt'"
      ],
      "metadata": {
        "id": "L47kY6_WKQeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_predictions(test_data, model):\n",
        "  predictions, gru_preds, t_preds = [], [], []\n",
        "  #model = model.to(torch.device('cpu'))\n",
        "  for i, batch in enumerate(test_data):\n",
        "    if i % 10 == 0:\n",
        "      print('batch:', i)\n",
        "\n",
        "    sent_id, masks = batch\n",
        "    \n",
        "    sent_id = sent_id.to(device)\n",
        "    masks = masks.to(device)\n",
        "    output = model(sent_id, masks)\n",
        "    preds = F.softmax(output, dim=1).argmax(1)\n",
        "    predictions += preds.tolist()\n",
        "  return predictions\n",
        "  #return gru_preds, t_preds"
      ],
      "metadata": {
        "id": "tzavTZExGF_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = perform_predictions(test_dataloader, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npBMI1n7_l4a",
        "outputId": "be3bc950-6070-4390-ec87-0cafc2d1f142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 0\n",
            "batch: 10\n",
            "batch: 20\n",
            "batch: 30\n",
            "batch: 40\n",
            "batch: 50\n",
            "batch: 60\n",
            "batch: 70\n",
            "batch: 80\n",
            "batch: 90\n",
            "batch: 100\n",
            "batch: 110\n",
            "batch: 120\n",
            "batch: 130\n",
            "batch: 140\n",
            "batch: 150\n",
            "batch: 160\n",
            "batch: 170\n",
            "batch: 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_predictions(preds)"
      ],
      "metadata": {
        "id": "cOane_VoR6Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATALOADER FOR MODELS ABOVE"
      ],
      "metadata": {
        "id": "ByPGqaxWyVFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = aggr_dataset(X_train, y_train, vocab, w2idx, embeddings_matrix, tk, train_seq, train_mask)\n",
        "val_dataset = aggr_dataset(X_val, y_val, vocab, w2idx, embeddings_matrix, tk, val_seq, val_mask)\n",
        "test_dataset = aggr_dataset(X_test, None, vocab, w2idx, embeddings_matrix, tk, test_seq, test_mask)"
      ],
      "metadata": {
        "id": "PXDo8O65b29G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, ConcatDataset\n",
        "#define a batch size\n",
        "batch_size = 8\n",
        "\n",
        "# sampler and dataloader\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size, collate_fn=train_dataset.collate_fn)\n",
        "\n",
        "# sampler and dataloader for val\n",
        "val_sampler = SequentialSampler(val_dataset)\n",
        "val_dataloader = DataLoader(val_dataset, sampler = val_sampler, batch_size=batch_size, collate_fn=val_dataset.collate_fn)\n",
        "\n",
        "# dataloader for test\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=test_dataset.collate_fn)"
      ],
      "metadata": {
        "id": "x2H0Mi8gcIbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU/LSTM and Robertuito"
      ],
      "metadata": {
        "id": "2DSWCt9_LZRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BL(nn.Module):\n",
        "  def __init__(self, bert, gru):\n",
        "      super(BL, self).__init__()\n",
        "      '''\n",
        "      Input:\n",
        "          bert: pre-trained bert model\n",
        "      '''\n",
        "\n",
        "      self.bert = bert # pretrained\n",
        "      self.gru  = gru\n",
        "      self.down = nn.Linear(4, 2, bias=True)\n",
        "      \n",
        "      \n",
        "  def forward(self, gru_id, gru_len, sent_id, mask):\n",
        "      # Get cls token\n",
        "      x = self.bert(sent_id, attention_mask=mask, return_dict=False)[0]\n",
        "      x_g = self.gru(gru_id, gru_len)[0]\n",
        "\n",
        "      x = torch.concat([x_g, x], dim=1)\n",
        "      x = self.down(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "9SLX6TN0Pf11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "robertuito2_bl = AutoModelForSequenceClassification.from_pretrained(\"pysentimiento/robertuito-base-uncased\")\n",
        "robertuito2_bl = robertuito2_bl.to(device)\n",
        "\n",
        "bl = BL(robertuito2_bl, model)\n",
        "bl = bl.to(device)"
      ],
      "metadata": {
        "id": "9uvx3MSdQT6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a34f65a-2da6-4a9e-d2b5-c633f44bec56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimizer\n",
        "from transformers import AdamW # optimizer\n",
        "optimizer2 = AdamW(bl.parameters(), lr = 1e-5, correct_bias=False) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I89Zvubuk1As",
        "outputId": "951eb6de-7c4d-43ec-8d2c-47b4a48553d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train():\n",
        "    \n",
        "    bl.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "  \n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        #batch = [r.to(device) for r in batch]\n",
        " \n",
        "        gruid, grulen, labels, _, sent_id, mask = batch\n",
        "        gruid = gruid.to(device)\n",
        "        labels = labels.to(device)\n",
        "        sent_id =sent_id.to(device)\n",
        "        mask = mask.to(device)\n",
        "        \n",
        "        # clear previously calculated gradients \n",
        "        bl.zero_grad()  \n",
        "        \n",
        "        # get model predictions for the current batch\n",
        "        preds = bl(gruid, grulen, sent_id, mask)\n",
        "        preds = F.log_softmax(preds, dim=1)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(bl.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer2.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "bSataV_wQNZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "  \n",
        "    # deactivate dropout layers\n",
        "    bl.eval()\n",
        "    \n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "        \n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "            # Calculate elapsed time in minutes.\n",
        "            #elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        #batch = [t.to(device) for t in batch]\n",
        "\n",
        "        gruid, grulen, labels, _, sent_id, mask  = batch\n",
        "        gruid = gruid.to(device)\n",
        "        labels = labels.to(device)\n",
        "        sent_id =sent_id.to(device)\n",
        "        mask = mask.to(device)\n",
        "        \n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # model predictions\n",
        "            preds = bl(gruid, grulen, sent_id, mask)\n",
        "            lab = F.log_softmax(preds, dim=1).argmax(1)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "            total_preds.append(preds)\n",
        "        \n",
        "        predictions += lab.cpu().tolist()\n",
        "        targets += labels.cpu().tolist()\n",
        "\n",
        "    \n",
        "    metric = accuracy_score(targets, predictions)\n",
        "    print(metric)\n",
        "    \n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "JlCmWTMiRgDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "#for each epoch\n",
        "for epoch in range(3):     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    #save the best model\n",
        "    torch.save(bl.state_dict(), 'saved_weights'+str(epoch)+'.pt')\n",
        "    # Results\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY7bMZRJlFjo",
        "outputId": "bd625d59-f67e-4df1-80b1-0eafb7aa549b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of    785.\n",
            "  Batch   100  of    785.\n",
            "  Batch   150  of    785.\n",
            "  Batch   200  of    785.\n",
            "  Batch   250  of    785.\n",
            "  Batch   300  of    785.\n",
            "  Batch   350  of    785.\n",
            "  Batch   400  of    785.\n",
            "  Batch   450  of    785.\n",
            "  Batch   500  of    785.\n",
            "  Batch   550  of    785.\n",
            "  Batch   600  of    785.\n",
            "  Batch   650  of    785.\n",
            "  Batch   700  of    785.\n",
            "  Batch   750  of    785.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.9045996592844975\n",
            "\n",
            "Training Loss: 0.380\n",
            "Validation Loss: -1.870\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of    785.\n",
            "  Batch   100  of    785.\n",
            "  Batch   150  of    785.\n",
            "  Batch   200  of    785.\n",
            "  Batch   250  of    785.\n",
            "  Batch   300  of    785.\n",
            "  Batch   350  of    785.\n",
            "  Batch   400  of    785.\n",
            "  Batch   450  of    785.\n",
            "  Batch   500  of    785.\n",
            "  Batch   550  of    785.\n",
            "  Batch   600  of    785.\n",
            "  Batch   650  of    785.\n",
            "  Batch   700  of    785.\n",
            "  Batch   750  of    785.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.8977853492333902\n",
            "\n",
            "Training Loss: 0.193\n",
            "Validation Loss: -2.459\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of    785.\n",
            "  Batch   100  of    785.\n",
            "  Batch   150  of    785.\n",
            "  Batch   200  of    785.\n",
            "  Batch   250  of    785.\n",
            "  Batch   300  of    785.\n",
            "  Batch   350  of    785.\n",
            "  Batch   400  of    785.\n",
            "  Batch   450  of    785.\n",
            "  Batch   500  of    785.\n",
            "  Batch   550  of    785.\n",
            "  Batch   600  of    785.\n",
            "  Batch   650  of    785.\n",
            "  Batch   700  of    785.\n",
            "  Batch   750  of    785.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.889267461669506\n",
            "\n",
            "Training Loss: 0.097\n",
            "Validation Loss: -2.870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bl.load_state_dict(torch.load('saved_weights0.pt'))\n",
        "bl.eval()\n",
        "evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0nah_LRE1zQ",
        "outputId": "06544c9a-263b-4649-806c-50926c7c5339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.9045996592844975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.8698840769561562, array([[-0.40309802,  0.55115736],\n",
              "        [ 2.852524  , -1.2707568 ],\n",
              "        [-2.4587746 ,  1.7125113 ],\n",
              "        ...,\n",
              "        [ 3.3337648 , -1.9552519 ],\n",
              "        [ 1.5371989 , -0.6677473 ],\n",
              "        [ 0.04977982,  0.40633646]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_predictions(test_data):\n",
        "  predictions, gru_preds, t_preds = [], [], []\n",
        "  #model = model.to(torch.device('cpu'))\n",
        "  for i, data in enumerate(test_data):\n",
        "    if i % 10 == 0:\n",
        "      print('batch:', i)\n",
        "\n",
        "    seq, seq_len, _, _, tids, masks = data\n",
        "    \n",
        "    seq = seq.to(device)\n",
        "    tids = tids.to(device)\n",
        "    masks = masks.to(device)\n",
        "    output = bl(seq, seq_len, tids, masks)\n",
        "    preds = F.log_softmax(output, dim=1).argmax(1)\n",
        "    predictions += preds.tolist()\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "Wme0902L_VGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = perform_predictions(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUSX7DlIUfoN",
        "outputId": "7ca43db7-b03c-41c7-f477-e32942fc330e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 0\n",
            "batch: 10\n",
            "batch: 20\n",
            "batch: 30\n",
            "batch: 40\n",
            "batch: 50\n",
            "batch: 60\n",
            "batch: 70\n",
            "batch: 80\n",
            "batch: 90\n",
            "batch: 100\n",
            "batch: 110\n",
            "batch: 120\n",
            "batch: 130\n",
            "batch: 140\n",
            "batch: 150\n",
            "batch: 160\n",
            "batch: 170\n",
            "batch: 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_predictions(preds)"
      ],
      "metadata": {
        "id": "wAT-P1tJUqgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  '/content/saved_weights2.pt' '/content/drive/MyDrive/Colab_Notebooks/NLP/'"
      ],
      "metadata": {
        "id": "iKkD6vLX--Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting Scheme"
      ],
      "metadata": {
        "id": "FuRz2HUIxfXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate_both():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "  \n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "        gruid, grulen, labels, _, sent_id, mask  = batch\n",
        "        gruid = gruid.to(device)\n",
        "        labels = labels.to(device)\n",
        "        sent_id =sent_id.to(device)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # model predictions\n",
        "            preds = model2(sent_id, mask)\n",
        "            preds_bl = bl(gruid, grulen, sent_id, mask)\n",
        "\n",
        "            lab1 = F.log_softmax(preds, dim=1)\n",
        "            lab2 = F.log_softmax(preds_bl, dim=1)\n",
        "\n",
        "            lab2 = (lab1 + lab2)/2\n",
        "            lab = lab2.argmax(1)\n",
        "\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            total_preds.append(preds)\n",
        "        \n",
        "        predictions += lab.cpu().tolist()\n",
        "        targets += labels.cpu().tolist()\n",
        "\n",
        "    metric = accuracy_score(targets, predictions)\n",
        "    print(metric)\n",
        "    \n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "DKM7JZpzpjro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_both()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg-eutUwq2zu",
        "outputId": "a6cfe342-7ebf-4a9d-94a9-114ede8452c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n",
            "0.9063032367972743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.475469028224816, array([[ 1.8261124, -1.7547202],\n",
              "        [ 4.868897 , -5.156266 ],\n",
              "        [-4.467583 ,  4.572062 ],\n",
              "        ...,\n",
              "        [ 4.455827 , -5.1700225],\n",
              "        [ 1.7008258, -2.2183805],\n",
              "        [ 4.0854645, -4.737025 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_predictions(test_data):\n",
        "  predictions, gru_preds, t_preds = [], [], []\n",
        "  #model = model.to(torch.device('cpu'))\n",
        "  for i, data in enumerate(test_data):\n",
        "    if i % 10 == 0:\n",
        "      print('batch:', i)\n",
        "\n",
        "    gruid, grulen, _, _, sent_id, mask = data\n",
        "    gruid = gruid.to(device)\n",
        "    sent_id =sent_id.to(device)\n",
        "    mask = mask.to(device)\n",
        "    \n",
        "    preds = model2(sent_id, mask)\n",
        "    preds_bl = bl(gruid, grulen, sent_id, mask)\n",
        "\n",
        "    lab1 = F.log_softmax(preds, dim=1)\n",
        "    lab2 = F.log_softmax(preds_bl, dim=1)\n",
        "\n",
        "    lab2 = (lab1 + lab2)/2\n",
        "    lab = lab2.argmax(1)\n",
        "\n",
        "    predictions += lab.cpu().tolist()\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "ZLH-7dkyq_s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = perform_predictions(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGf83CM0rmG9",
        "outputId": "4b58b103-d0ed-49db-d350-efee11e8cd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 0\n",
            "batch: 10\n",
            "batch: 20\n",
            "batch: 30\n",
            "batch: 40\n",
            "batch: 50\n",
            "batch: 60\n",
            "batch: 70\n",
            "batch: 80\n",
            "batch: 90\n",
            "batch: 100\n",
            "batch: 110\n",
            "batch: 120\n",
            "batch: 130\n",
            "batch: 140\n",
            "batch: 150\n",
            "batch: 160\n",
            "batch: 170\n",
            "batch: 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_predictions(preds)"
      ],
      "metadata": {
        "id": "6y55z65ervlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model Weights"
      ],
      "metadata": {
        "id": "wv6p23htWKou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bl.state_dict(), 'BL_best_saved_weights2.pt')"
      ],
      "metadata": {
        "id": "_otxhRQquasE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(), 'model2_best_saved_weights2.pt')"
      ],
      "metadata": {
        "id": "0BjiVd4swjPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  '/content/BL_best_saved_weights2.pt' '/content/drive/MyDrive/Colab_Notebooks/NLP/'"
      ],
      "metadata": {
        "id": "74DMRE25wwXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  '/content/model2_best_saved_weights2.pt' '/content/drive/MyDrive/Colab_Notebooks/NLP/'"
      ],
      "metadata": {
        "id": "btcLI4KyxBVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADD Robertuito and Robertuito_GRU/LSTM"
      ],
      "metadata": {
        "id": "NJURXCgii2JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BL_B(nn.Module):\n",
        "  def __init__(self, bl, model2):\n",
        "      super(BL_B, self).__init__()\n",
        "      '''\n",
        "      Input:\n",
        "          bert: pre-trained bert model\n",
        "      '''\n",
        "\n",
        "      self.bl = bl # pretrained\n",
        "      self.model2  = model2\n",
        "      \n",
        "      \n",
        "  def forward(self, gruid, grulen, sent_id, mask):\n",
        "      # Get cls token\n",
        "      preds = self.model2(sent_id, mask)\n",
        "      preds_bl = self.bl(gruid, grulen, sent_id, mask)\n",
        "\n",
        "      lab1 = F.log_softmax(preds, dim=1)\n",
        "      lab2 = F.log_softmax(preds_bl, dim=1)\n",
        "\n",
        "      lab2 = (lab1 + lab2)/2\n",
        "      \n",
        "      return lab2"
      ],
      "metadata": {
        "id": "aygJPJHhbRkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bl_b = BL_B(bl, model2)"
      ],
      "metadata": {
        "id": "IuQHqEIucO5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW # optimizer\n",
        "optimizer_bl = AdamW(bl_b.parameters(), lr = 1e-5, correct_bias=False) "
      ],
      "metadata": {
        "id": "U1OE3GFucTPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train():\n",
        "    \n",
        "    bl_b.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "  \n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        #batch = [r.to(device) for r in batch]\n",
        " \n",
        "        gruid, grulen, labels, _, sent_id, mask = batch\n",
        "        gruid = gruid.to(device)\n",
        "        labels = labels.to(device)\n",
        "        sent_id =sent_id.to(device)\n",
        "        mask = mask.to(device)\n",
        "        \n",
        "        # clear previously calculated gradients \n",
        "        bl_b.zero_grad()  \n",
        "        \n",
        "        # get model predictions for the current batch\n",
        "        preds = bl_b(gruid, grulen, sent_id, mask)\n",
        "        \n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        #torch.nn.utils.clip_grad_norm_(bl_b.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer_bl.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "2rGRvcpTcB6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "  \n",
        "    # deactivate dropout layers\n",
        "    bl_b.eval()\n",
        "    \n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "        \n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "            # Calculate elapsed time in minutes.\n",
        "            #elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        #batch = [t.to(device) for t in batch]\n",
        "\n",
        "        gruid, grulen, labels, _, sent_id, mask  = batch\n",
        "        gruid = gruid.to(device)\n",
        "        labels = labels.to(device)\n",
        "        sent_id =sent_id.to(device)\n",
        "        mask = mask.to(device)\n",
        "        \n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # model predictions\n",
        "            preds = bl_b(gruid, grulen, sent_id, mask)\n",
        "            lab = preds.argmax(1)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "            total_preds.append(preds)\n",
        "        \n",
        "        predictions += lab.cpu().tolist()\n",
        "        targets += labels.cpu().tolist()\n",
        "\n",
        "    \n",
        "    metric = accuracy_score(targets, predictions)\n",
        "    print(metric)\n",
        "    \n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "njEKXPXpczFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "#for each epoch\n",
        "for epoch in range(4):     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    #save the best model\n",
        "    torch.save(bl_b.state_dict(), 'bl_b_saved_weights'+str(epoch)+'.pt')\n",
        "    # Results\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV4JPeOedT_b",
        "outputId": "d3878bb5-ec79-4b5b-cf6c-91a10ba3f2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 3\n",
            "  Batch    50  of  1,035.\n",
            "  Batch   100  of  1,035.\n",
            "  Batch   150  of  1,035.\n",
            "  Batch   200  of  1,035.\n",
            "  Batch   250  of  1,035.\n",
            "  Batch   300  of  1,035.\n",
            "  Batch   350  of  1,035.\n",
            "  Batch   400  of  1,035.\n",
            "  Batch   450  of  1,035.\n",
            "  Batch   500  of  1,035.\n",
            "  Batch   550  of  1,035.\n",
            "  Batch   600  of  1,035.\n",
            "  Batch   650  of  1,035.\n",
            "  Batch   700  of  1,035.\n",
            "  Batch   750  of  1,035.\n",
            "  Batch   800  of  1,035.\n",
            "  Batch   850  of  1,035.\n",
            "  Batch   900  of  1,035.\n",
            "  Batch   950  of  1,035.\n",
            "  Batch 1,000  of  1,035.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.8739352640545145\n",
            "\n",
            "Training Loss: 0.263\n",
            "Validation Loss: 0.271\n",
            "\n",
            " Epoch 2 / 3\n",
            "  Batch    50  of  1,035.\n",
            "  Batch   100  of  1,035.\n",
            "  Batch   150  of  1,035.\n",
            "  Batch   200  of  1,035.\n",
            "  Batch   250  of  1,035.\n",
            "  Batch   300  of  1,035.\n",
            "  Batch   350  of  1,035.\n",
            "  Batch   400  of  1,035.\n",
            "  Batch   450  of  1,035.\n",
            "  Batch   500  of  1,035.\n",
            "  Batch   550  of  1,035.\n",
            "  Batch   600  of  1,035.\n",
            "  Batch   650  of  1,035.\n",
            "  Batch   700  of  1,035.\n",
            "  Batch   750  of  1,035.\n",
            "  Batch   800  of  1,035.\n",
            "  Batch   850  of  1,035.\n",
            "  Batch   900  of  1,035.\n",
            "  Batch   950  of  1,035.\n",
            "  Batch 1,000  of  1,035.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.909710391822828\n",
            "\n",
            "Training Loss: 0.101\n",
            "Validation Loss: 0.339\n",
            "\n",
            " Epoch 3 / 3\n",
            "  Batch    50  of  1,035.\n",
            "  Batch   100  of  1,035.\n",
            "  Batch   150  of  1,035.\n",
            "  Batch   200  of  1,035.\n",
            "  Batch   250  of  1,035.\n",
            "  Batch   300  of  1,035.\n",
            "  Batch   350  of  1,035.\n",
            "  Batch   400  of  1,035.\n",
            "  Batch   450  of  1,035.\n",
            "  Batch   500  of  1,035.\n",
            "  Batch   550  of  1,035.\n",
            "  Batch   600  of  1,035.\n",
            "  Batch   650  of  1,035.\n",
            "  Batch   700  of  1,035.\n",
            "  Batch   750  of  1,035.\n",
            "  Batch   800  of  1,035.\n",
            "  Batch   850  of  1,035.\n",
            "  Batch   900  of  1,035.\n",
            "  Batch   950  of  1,035.\n",
            "  Batch 1,000  of  1,035.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.9028960817717206\n",
            "\n",
            "Training Loss: 0.051\n",
            "Validation Loss: 0.395\n",
            "\n",
            " Epoch 4 / 3\n",
            "  Batch    50  of  1,035.\n",
            "  Batch   100  of  1,035.\n",
            "  Batch   150  of  1,035.\n",
            "  Batch   200  of  1,035.\n",
            "  Batch   250  of  1,035.\n",
            "  Batch   300  of  1,035.\n",
            "  Batch   350  of  1,035.\n",
            "  Batch   400  of  1,035.\n",
            "  Batch   450  of  1,035.\n",
            "  Batch   500  of  1,035.\n",
            "  Batch   550  of  1,035.\n",
            "  Batch   600  of  1,035.\n",
            "  Batch   650  of  1,035.\n",
            "  Batch   700  of  1,035.\n",
            "  Batch   750  of  1,035.\n",
            "  Batch   800  of  1,035.\n",
            "  Batch   850  of  1,035.\n",
            "  Batch   900  of  1,035.\n",
            "  Batch   950  of  1,035.\n",
            "  Batch 1,000  of  1,035.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.9011925042589438\n",
            "\n",
            "Training Loss: 0.025\n",
            "Validation Loss: 0.425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bl_b.load_state_dict(torch.load('/content/drive/MyDrive/Colab_Notebooks/NLP/best_add_rob_lstmandrob_model.pt'))\n",
        "bl_b.load_state_dict(torch.load('/content/bl_b_saved_weights1.pt'))\n",
        "bl_b.eval()\n",
        "evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKXvEGQWh6Ta",
        "outputId": "e7101dce-ad01-457c-c9eb-1f84f6ba3443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n",
            "  Batch    50  of     74.\n",
            "0.909710391822828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3386003353909866, array([[-5.3767794e-01, -8.8077027e-01],\n",
              "        [-5.1078359e-03, -5.3812809e+00],\n",
              "        [-5.2420754e+00, -6.8170829e-03],\n",
              "        ...,\n",
              "        [-5.0165886e-03, -5.4053106e+00],\n",
              "        [-4.8928417e-02, -3.6009932e+00],\n",
              "        [-5.3122920e-01, -9.4185311e-01]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_predictions(test_data):\n",
        "  predictions, gru_preds, t_preds = [], [], []\n",
        "  #model = model.to(torch.device('cpu'))\n",
        "  for i, data in enumerate(test_data):\n",
        "    if i % 10 == 0:\n",
        "      print('batch:', i)\n",
        "\n",
        "    gruid, grulen, _, _, sent_id, mask = data\n",
        "    gruid = gruid.to(device)\n",
        "    sent_id =sent_id.to(device)\n",
        "    mask = mask.to(device)\n",
        "    \n",
        "    preds = bl_b(gruid, grulen, sent_id, mask)\n",
        "\n",
        "    lab = preds.argmax(1)\n",
        "\n",
        "    predictions += lab.cpu().tolist()\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "hIO8LQvNfAP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = perform_predictions(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKoXcNyFfIcx",
        "outputId": "d145ad6b-25c1-4307-ec1e-c2d7f6e885f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 0\n",
            "batch: 10\n",
            "batch: 20\n",
            "batch: 30\n",
            "batch: 40\n",
            "batch: 50\n",
            "batch: 60\n",
            "batch: 70\n",
            "batch: 80\n",
            "batch: 90\n",
            "batch: 100\n",
            "batch: 110\n",
            "batch: 120\n",
            "batch: 130\n",
            "batch: 140\n",
            "batch: 150\n",
            "batch: 160\n",
            "batch: 170\n",
            "batch: 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_predictions(preds)"
      ],
      "metadata": {
        "id": "TomyfUjyfTMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad54eb8-ea24-4cff-bc84-de6fca7ff192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id,Expected\n",
            "0,0\n",
            "1,0\n",
            "2,0\n",
            "3,1\n",
            "4,0\n",
            "5,0\n",
            "6,0\n",
            "7,0\n",
            "8,1\n",
            "9,0\n",
            "10,0\n",
            "11,0\n",
            "12,0\n",
            "13,0\n",
            "14,1\n",
            "15,0\n",
            "16,0\n",
            "17,0\n",
            "18,0\n",
            "19,0\n",
            "20,1\n",
            "21,0\n",
            "22,0\n",
            "23,1\n",
            "24,0\n",
            "25,1\n",
            "26,0\n",
            "27,0\n",
            "28,0\n",
            "29,0\n",
            "30,1\n",
            "31,0\n",
            "32,0\n",
            "33,0\n",
            "34,1\n",
            "35,1\n",
            "36,1\n",
            "37,1\n",
            "38,0\n",
            "39,0\n",
            "40,0\n",
            "41,0\n",
            "42,1\n",
            "43,0\n",
            "44,0\n",
            "45,1\n",
            "46,1\n",
            "47,0\n",
            "48,0\n",
            "49,0\n",
            "50,1\n",
            "51,0\n",
            "52,0\n",
            "53,1\n",
            "54,0\n",
            "55,0\n",
            "56,0\n",
            "57,1\n",
            "58,0\n",
            "59,1\n",
            "60,1\n",
            "61,1\n",
            "62,0\n",
            "63,0\n",
            "64,0\n",
            "65,1\n",
            "66,0\n",
            "67,0\n",
            "68,0\n",
            "69,0\n",
            "70,1\n",
            "71,0\n",
            "72,1\n",
            "73,0\n",
            "74,0\n",
            "75,1\n",
            "76,0\n",
            "77,0\n",
            "78,1\n",
            "79,0\n",
            "80,0\n",
            "81,0\n",
            "82,1\n",
            "83,0\n",
            "84,0\n",
            "85,0\n",
            "86,0\n",
            "87,1\n",
            "88,0\n",
            "89,1\n",
            "90,0\n",
            "91,0\n",
            "92,1\n",
            "93,1\n",
            "94,1\n",
            "95,0\n",
            "96,1\n",
            "97,1\n",
            "98,1\n",
            "99,0\n",
            "100,0\n",
            "101,0\n",
            "102,0\n",
            "103,1\n",
            "104,1\n",
            "105,1\n",
            "106,1\n",
            "107,0\n",
            "108,0\n",
            "109,0\n",
            "110,0\n",
            "111,0\n",
            "112,0\n",
            "113,0\n",
            "114,0\n",
            "115,0\n",
            "116,0\n",
            "117,1\n",
            "118,1\n",
            "119,0\n",
            "120,0\n",
            "121,0\n",
            "122,1\n",
            "123,0\n",
            "124,0\n",
            "125,0\n",
            "126,0\n",
            "127,1\n",
            "128,0\n",
            "129,1\n",
            "130,0\n",
            "131,0\n",
            "132,0\n",
            "133,0\n",
            "134,1\n",
            "135,0\n",
            "136,0\n",
            "137,0\n",
            "138,0\n",
            "139,0\n",
            "140,1\n",
            "141,1\n",
            "142,0\n",
            "143,0\n",
            "144,0\n",
            "145,0\n",
            "146,1\n",
            "147,0\n",
            "148,1\n",
            "149,0\n",
            "150,0\n",
            "151,0\n",
            "152,0\n",
            "153,0\n",
            "154,0\n",
            "155,0\n",
            "156,1\n",
            "157,0\n",
            "158,0\n",
            "159,1\n",
            "160,0\n",
            "161,0\n",
            "162,0\n",
            "163,0\n",
            "164,0\n",
            "165,1\n",
            "166,1\n",
            "167,1\n",
            "168,0\n",
            "169,0\n",
            "170,0\n",
            "171,0\n",
            "172,0\n",
            "173,0\n",
            "174,0\n",
            "175,0\n",
            "176,0\n",
            "177,0\n",
            "178,0\n",
            "179,1\n",
            "180,1\n",
            "181,0\n",
            "182,0\n",
            "183,1\n",
            "184,0\n",
            "185,1\n",
            "186,0\n",
            "187,0\n",
            "188,0\n",
            "189,1\n",
            "190,1\n",
            "191,1\n",
            "192,0\n",
            "193,0\n",
            "194,0\n",
            "195,1\n",
            "196,1\n",
            "197,0\n",
            "198,0\n",
            "199,1\n",
            "200,1\n",
            "201,0\n",
            "202,0\n",
            "203,1\n",
            "204,1\n",
            "205,1\n",
            "206,0\n",
            "207,1\n",
            "208,1\n",
            "209,0\n",
            "210,0\n",
            "211,1\n",
            "212,1\n",
            "213,0\n",
            "214,0\n",
            "215,0\n",
            "216,0\n",
            "217,0\n",
            "218,0\n",
            "219,0\n",
            "220,0\n",
            "221,0\n",
            "222,1\n",
            "223,0\n",
            "224,0\n",
            "225,1\n",
            "226,1\n",
            "227,0\n",
            "228,0\n",
            "229,0\n",
            "230,1\n",
            "231,0\n",
            "232,1\n",
            "233,1\n",
            "234,0\n",
            "235,1\n",
            "236,0\n",
            "237,1\n",
            "238,0\n",
            "239,1\n",
            "240,0\n",
            "241,0\n",
            "242,1\n",
            "243,0\n",
            "244,0\n",
            "245,0\n",
            "246,0\n",
            "247,1\n",
            "248,0\n",
            "249,1\n",
            "250,0\n",
            "251,1\n",
            "252,0\n",
            "253,1\n",
            "254,0\n",
            "255,1\n",
            "256,0\n",
            "257,0\n",
            "258,0\n",
            "259,1\n",
            "260,0\n",
            "261,1\n",
            "262,0\n",
            "263,1\n",
            "264,0\n",
            "265,0\n",
            "266,0\n",
            "267,1\n",
            "268,1\n",
            "269,0\n",
            "270,1\n",
            "271,1\n",
            "272,0\n",
            "273,0\n",
            "274,0\n",
            "275,0\n",
            "276,0\n",
            "277,1\n",
            "278,0\n",
            "279,0\n",
            "280,0\n",
            "281,0\n",
            "282,0\n",
            "283,1\n",
            "284,1\n",
            "285,0\n",
            "286,0\n",
            "287,1\n",
            "288,0\n",
            "289,1\n",
            "290,1\n",
            "291,0\n",
            "292,0\n",
            "293,0\n",
            "294,0\n",
            "295,1\n",
            "296,0\n",
            "297,0\n",
            "298,0\n",
            "299,0\n",
            "300,0\n",
            "301,0\n",
            "302,0\n",
            "303,0\n",
            "304,1\n",
            "305,1\n",
            "306,1\n",
            "307,1\n",
            "308,1\n",
            "309,0\n",
            "310,1\n",
            "311,0\n",
            "312,1\n",
            "313,0\n",
            "314,0\n",
            "315,0\n",
            "316,1\n",
            "317,0\n",
            "318,0\n",
            "319,0\n",
            "320,1\n",
            "321,0\n",
            "322,0\n",
            "323,0\n",
            "324,0\n",
            "325,0\n",
            "326,0\n",
            "327,1\n",
            "328,0\n",
            "329,0\n",
            "330,0\n",
            "331,0\n",
            "332,0\n",
            "333,1\n",
            "334,1\n",
            "335,0\n",
            "336,0\n",
            "337,0\n",
            "338,1\n",
            "339,0\n",
            "340,0\n",
            "341,0\n",
            "342,0\n",
            "343,0\n",
            "344,0\n",
            "345,1\n",
            "346,0\n",
            "347,0\n",
            "348,0\n",
            "349,1\n",
            "350,0\n",
            "351,0\n",
            "352,1\n",
            "353,0\n",
            "354,0\n",
            "355,0\n",
            "356,1\n",
            "357,1\n",
            "358,1\n",
            "359,1\n",
            "360,0\n",
            "361,0\n",
            "362,0\n",
            "363,1\n",
            "364,0\n",
            "365,1\n",
            "366,0\n",
            "367,1\n",
            "368,1\n",
            "369,1\n",
            "370,0\n",
            "371,1\n",
            "372,0\n",
            "373,0\n",
            "374,0\n",
            "375,0\n",
            "376,0\n",
            "377,1\n",
            "378,1\n",
            "379,0\n",
            "380,0\n",
            "381,0\n",
            "382,0\n",
            "383,0\n",
            "384,0\n",
            "385,0\n",
            "386,1\n",
            "387,0\n",
            "388,1\n",
            "389,0\n",
            "390,0\n",
            "391,0\n",
            "392,0\n",
            "393,0\n",
            "394,0\n",
            "395,1\n",
            "396,0\n",
            "397,0\n",
            "398,0\n",
            "399,1\n",
            "400,0\n",
            "401,0\n",
            "402,0\n",
            "403,0\n",
            "404,0\n",
            "405,0\n",
            "406,0\n",
            "407,0\n",
            "408,0\n",
            "409,1\n",
            "410,0\n",
            "411,1\n",
            "412,0\n",
            "413,0\n",
            "414,0\n",
            "415,1\n",
            "416,0\n",
            "417,0\n",
            "418,0\n",
            "419,0\n",
            "420,0\n",
            "421,1\n",
            "422,0\n",
            "423,1\n",
            "424,0\n",
            "425,0\n",
            "426,1\n",
            "427,0\n",
            "428,1\n",
            "429,0\n",
            "430,0\n",
            "431,0\n",
            "432,1\n",
            "433,0\n",
            "434,0\n",
            "435,0\n",
            "436,0\n",
            "437,1\n",
            "438,1\n",
            "439,0\n",
            "440,0\n",
            "441,0\n",
            "442,0\n",
            "443,0\n",
            "444,0\n",
            "445,0\n",
            "446,0\n",
            "447,0\n",
            "448,1\n",
            "449,0\n",
            "450,0\n",
            "451,1\n",
            "452,0\n",
            "453,0\n",
            "454,1\n",
            "455,0\n",
            "456,0\n",
            "457,1\n",
            "458,0\n",
            "459,1\n",
            "460,1\n",
            "461,0\n",
            "462,0\n",
            "463,0\n",
            "464,0\n",
            "465,0\n",
            "466,0\n",
            "467,1\n",
            "468,0\n",
            "469,0\n",
            "470,0\n",
            "471,1\n",
            "472,0\n",
            "473,0\n",
            "474,0\n",
            "475,0\n",
            "476,0\n",
            "477,1\n",
            "478,0\n",
            "479,0\n",
            "480,1\n",
            "481,1\n",
            "482,0\n",
            "483,0\n",
            "484,1\n",
            "485,0\n",
            "486,0\n",
            "487,1\n",
            "488,1\n",
            "489,0\n",
            "490,0\n",
            "491,1\n",
            "492,0\n",
            "493,0\n",
            "494,0\n",
            "495,0\n",
            "496,0\n",
            "497,0\n",
            "498,1\n",
            "499,0\n",
            "500,0\n",
            "501,0\n",
            "502,1\n",
            "503,1\n",
            "504,1\n",
            "505,1\n",
            "506,0\n",
            "507,0\n",
            "508,0\n",
            "509,1\n",
            "510,0\n",
            "511,1\n",
            "512,1\n",
            "513,0\n",
            "514,1\n",
            "515,0\n",
            "516,0\n",
            "517,0\n",
            "518,0\n",
            "519,0\n",
            "520,0\n",
            "521,0\n",
            "522,0\n",
            "523,1\n",
            "524,0\n",
            "525,0\n",
            "526,0\n",
            "527,0\n",
            "528,0\n",
            "529,1\n",
            "530,1\n",
            "531,1\n",
            "532,1\n",
            "533,0\n",
            "534,0\n",
            "535,1\n",
            "536,1\n",
            "537,1\n",
            "538,1\n",
            "539,0\n",
            "540,0\n",
            "541,1\n",
            "542,0\n",
            "543,0\n",
            "544,0\n",
            "545,0\n",
            "546,1\n",
            "547,0\n",
            "548,0\n",
            "549,0\n",
            "550,0\n",
            "551,0\n",
            "552,1\n",
            "553,0\n",
            "554,1\n",
            "555,0\n",
            "556,0\n",
            "557,0\n",
            "558,0\n",
            "559,0\n",
            "560,0\n",
            "561,0\n",
            "562,0\n",
            "563,1\n",
            "564,1\n",
            "565,0\n",
            "566,0\n",
            "567,0\n",
            "568,1\n",
            "569,0\n",
            "570,0\n",
            "571,0\n",
            "572,0\n",
            "573,0\n",
            "574,0\n",
            "575,0\n",
            "576,1\n",
            "577,0\n",
            "578,0\n",
            "579,0\n",
            "580,0\n",
            "581,0\n",
            "582,1\n",
            "583,1\n",
            "584,0\n",
            "585,0\n",
            "586,0\n",
            "587,0\n",
            "588,1\n",
            "589,1\n",
            "590,0\n",
            "591,0\n",
            "592,1\n",
            "593,0\n",
            "594,1\n",
            "595,1\n",
            "596,0\n",
            "597,0\n",
            "598,1\n",
            "599,1\n",
            "600,0\n",
            "601,0\n",
            "602,1\n",
            "603,0\n",
            "604,1\n",
            "605,0\n",
            "606,1\n",
            "607,0\n",
            "608,0\n",
            "609,0\n",
            "610,0\n",
            "611,1\n",
            "612,0\n",
            "613,1\n",
            "614,0\n",
            "615,0\n",
            "616,0\n",
            "617,0\n",
            "618,0\n",
            "619,0\n",
            "620,1\n",
            "621,0\n",
            "622,1\n",
            "623,1\n",
            "624,0\n",
            "625,0\n",
            "626,1\n",
            "627,1\n",
            "628,0\n",
            "629,0\n",
            "630,0\n",
            "631,0\n",
            "632,0\n",
            "633,1\n",
            "634,1\n",
            "635,0\n",
            "636,0\n",
            "637,0\n",
            "638,0\n",
            "639,1\n",
            "640,0\n",
            "641,1\n",
            "642,0\n",
            "643,1\n",
            "644,1\n",
            "645,1\n",
            "646,0\n",
            "647,0\n",
            "648,0\n",
            "649,1\n",
            "650,0\n",
            "651,1\n",
            "652,1\n",
            "653,1\n",
            "654,1\n",
            "655,0\n",
            "656,0\n",
            "657,0\n",
            "658,0\n",
            "659,0\n",
            "660,0\n",
            "661,0\n",
            "662,0\n",
            "663,0\n",
            "664,0\n",
            "665,1\n",
            "666,1\n",
            "667,1\n",
            "668,1\n",
            "669,0\n",
            "670,0\n",
            "671,0\n",
            "672,1\n",
            "673,1\n",
            "674,1\n",
            "675,1\n",
            "676,0\n",
            "677,0\n",
            "678,0\n",
            "679,1\n",
            "680,1\n",
            "681,0\n",
            "682,0\n",
            "683,0\n",
            "684,0\n",
            "685,0\n",
            "686,1\n",
            "687,0\n",
            "688,0\n",
            "689,0\n",
            "690,0\n",
            "691,0\n",
            "692,0\n",
            "693,0\n",
            "694,0\n",
            "695,0\n",
            "696,0\n",
            "697,0\n",
            "698,0\n",
            "699,1\n",
            "700,0\n",
            "701,0\n",
            "702,1\n",
            "703,1\n",
            "704,1\n",
            "705,0\n",
            "706,0\n",
            "707,0\n",
            "708,1\n",
            "709,1\n",
            "710,0\n",
            "711,0\n",
            "712,0\n",
            "713,0\n",
            "714,0\n",
            "715,0\n",
            "716,1\n",
            "717,1\n",
            "718,1\n",
            "719,0\n",
            "720,0\n",
            "721,0\n",
            "722,0\n",
            "723,0\n",
            "724,0\n",
            "725,0\n",
            "726,0\n",
            "727,1\n",
            "728,0\n",
            "729,0\n",
            "730,0\n",
            "731,0\n",
            "732,1\n",
            "733,0\n",
            "734,0\n",
            "735,1\n",
            "736,1\n",
            "737,0\n",
            "738,1\n",
            "739,1\n",
            "740,0\n",
            "741,1\n",
            "742,0\n",
            "743,1\n",
            "744,1\n",
            "745,0\n",
            "746,0\n",
            "747,0\n",
            "748,1\n",
            "749,0\n",
            "750,0\n",
            "751,0\n",
            "752,1\n",
            "753,0\n",
            "754,0\n",
            "755,1\n",
            "756,1\n",
            "757,0\n",
            "758,1\n",
            "759,1\n",
            "760,0\n",
            "761,1\n",
            "762,0\n",
            "763,0\n",
            "764,0\n",
            "765,1\n",
            "766,0\n",
            "767,0\n",
            "768,0\n",
            "769,0\n",
            "770,0\n",
            "771,1\n",
            "772,0\n",
            "773,0\n",
            "774,1\n",
            "775,0\n",
            "776,0\n",
            "777,1\n",
            "778,0\n",
            "779,1\n",
            "780,0\n",
            "781,0\n",
            "782,0\n",
            "783,1\n",
            "784,1\n",
            "785,1\n",
            "786,1\n",
            "787,0\n",
            "788,0\n",
            "789,1\n",
            "790,0\n",
            "791,1\n",
            "792,0\n",
            "793,1\n",
            "794,1\n",
            "795,1\n",
            "796,0\n",
            "797,0\n",
            "798,0\n",
            "799,0\n",
            "800,0\n",
            "801,0\n",
            "802,1\n",
            "803,1\n",
            "804,0\n",
            "805,0\n",
            "806,0\n",
            "807,0\n",
            "808,1\n",
            "809,0\n",
            "810,0\n",
            "811,0\n",
            "812,0\n",
            "813,0\n",
            "814,0\n",
            "815,0\n",
            "816,0\n",
            "817,0\n",
            "818,0\n",
            "819,0\n",
            "820,0\n",
            "821,0\n",
            "822,0\n",
            "823,0\n",
            "824,1\n",
            "825,0\n",
            "826,0\n",
            "827,1\n",
            "828,0\n",
            "829,0\n",
            "830,1\n",
            "831,0\n",
            "832,0\n",
            "833,0\n",
            "834,0\n",
            "835,0\n",
            "836,0\n",
            "837,1\n",
            "838,1\n",
            "839,1\n",
            "840,0\n",
            "841,1\n",
            "842,0\n",
            "843,1\n",
            "844,1\n",
            "845,0\n",
            "846,0\n",
            "847,0\n",
            "848,1\n",
            "849,0\n",
            "850,1\n",
            "851,0\n",
            "852,1\n",
            "853,0\n",
            "854,0\n",
            "855,0\n",
            "856,1\n",
            "857,0\n",
            "858,0\n",
            "859,1\n",
            "860,0\n",
            "861,0\n",
            "862,0\n",
            "863,0\n",
            "864,0\n",
            "865,1\n",
            "866,0\n",
            "867,0\n",
            "868,0\n",
            "869,0\n",
            "870,1\n",
            "871,0\n",
            "872,1\n",
            "873,0\n",
            "874,1\n",
            "875,0\n",
            "876,0\n",
            "877,0\n",
            "878,0\n",
            "879,0\n",
            "880,0\n",
            "881,0\n",
            "882,0\n",
            "883,1\n",
            "884,1\n",
            "885,1\n",
            "886,1\n",
            "887,0\n",
            "888,1\n",
            "889,0\n",
            "890,0\n",
            "891,1\n",
            "892,1\n",
            "893,0\n",
            "894,0\n",
            "895,0\n",
            "896,0\n",
            "897,0\n",
            "898,0\n",
            "899,0\n",
            "900,0\n",
            "901,0\n",
            "902,0\n",
            "903,0\n",
            "904,1\n",
            "905,0\n",
            "906,1\n",
            "907,0\n",
            "908,0\n",
            "909,1\n",
            "910,1\n",
            "911,0\n",
            "912,1\n",
            "913,1\n",
            "914,0\n",
            "915,0\n",
            "916,0\n",
            "917,0\n",
            "918,0\n",
            "919,0\n",
            "920,1\n",
            "921,0\n",
            "922,0\n",
            "923,1\n",
            "924,1\n",
            "925,1\n",
            "926,1\n",
            "927,1\n",
            "928,0\n",
            "929,1\n",
            "930,0\n",
            "931,0\n",
            "932,1\n",
            "933,0\n",
            "934,0\n",
            "935,1\n",
            "936,1\n",
            "937,0\n",
            "938,1\n",
            "939,0\n",
            "940,1\n",
            "941,1\n",
            "942,1\n",
            "943,1\n",
            "944,0\n",
            "945,0\n",
            "946,0\n",
            "947,1\n",
            "948,0\n",
            "949,0\n",
            "950,0\n",
            "951,0\n",
            "952,0\n",
            "953,1\n",
            "954,1\n",
            "955,0\n",
            "956,0\n",
            "957,0\n",
            "958,0\n",
            "959,0\n",
            "960,0\n",
            "961,1\n",
            "962,1\n",
            "963,0\n",
            "964,0\n",
            "965,0\n",
            "966,0\n",
            "967,0\n",
            "968,0\n",
            "969,0\n",
            "970,0\n",
            "971,0\n",
            "972,0\n",
            "973,0\n",
            "974,0\n",
            "975,0\n",
            "976,0\n",
            "977,0\n",
            "978,0\n",
            "979,0\n",
            "980,0\n",
            "981,0\n",
            "982,1\n",
            "983,0\n",
            "984,0\n",
            "985,0\n",
            "986,0\n",
            "987,0\n",
            "988,0\n",
            "989,0\n",
            "990,0\n",
            "991,0\n",
            "992,0\n",
            "993,0\n",
            "994,1\n",
            "995,1\n",
            "996,0\n",
            "997,0\n",
            "998,0\n",
            "999,1\n",
            "1000,1\n",
            "1001,0\n",
            "1002,0\n",
            "1003,0\n",
            "1004,0\n",
            "1005,1\n",
            "1006,0\n",
            "1007,1\n",
            "1008,1\n",
            "1009,0\n",
            "1010,0\n",
            "1011,1\n",
            "1012,1\n",
            "1013,0\n",
            "1014,1\n",
            "1015,0\n",
            "1016,0\n",
            "1017,0\n",
            "1018,1\n",
            "1019,1\n",
            "1020,0\n",
            "1021,1\n",
            "1022,0\n",
            "1023,0\n",
            "1024,0\n",
            "1025,1\n",
            "1026,0\n",
            "1027,0\n",
            "1028,1\n",
            "1029,0\n",
            "1030,1\n",
            "1031,0\n",
            "1032,1\n",
            "1033,0\n",
            "1034,1\n",
            "1035,0\n",
            "1036,1\n",
            "1037,1\n",
            "1038,0\n",
            "1039,0\n",
            "1040,0\n",
            "1041,0\n",
            "1042,0\n",
            "1043,0\n",
            "1044,0\n",
            "1045,0\n",
            "1046,1\n",
            "1047,1\n",
            "1048,0\n",
            "1049,0\n",
            "1050,0\n",
            "1051,0\n",
            "1052,0\n",
            "1053,0\n",
            "1054,0\n",
            "1055,1\n",
            "1056,0\n",
            "1057,0\n",
            "1058,0\n",
            "1059,1\n",
            "1060,0\n",
            "1061,1\n",
            "1062,0\n",
            "1063,0\n",
            "1064,0\n",
            "1065,0\n",
            "1066,0\n",
            "1067,0\n",
            "1068,0\n",
            "1069,0\n",
            "1070,0\n",
            "1071,0\n",
            "1072,0\n",
            "1073,0\n",
            "1074,0\n",
            "1075,0\n",
            "1076,0\n",
            "1077,1\n",
            "1078,1\n",
            "1079,0\n",
            "1080,1\n",
            "1081,0\n",
            "1082,1\n",
            "1083,0\n",
            "1084,0\n",
            "1085,0\n",
            "1086,0\n",
            "1087,1\n",
            "1088,0\n",
            "1089,1\n",
            "1090,0\n",
            "1091,0\n",
            "1092,0\n",
            "1093,0\n",
            "1094,0\n",
            "1095,0\n",
            "1096,0\n",
            "1097,0\n",
            "1098,0\n",
            "1099,0\n",
            "1100,0\n",
            "1101,0\n",
            "1102,1\n",
            "1103,0\n",
            "1104,0\n",
            "1105,1\n",
            "1106,1\n",
            "1107,0\n",
            "1108,0\n",
            "1109,1\n",
            "1110,1\n",
            "1111,0\n",
            "1112,1\n",
            "1113,0\n",
            "1114,0\n",
            "1115,1\n",
            "1116,0\n",
            "1117,1\n",
            "1118,1\n",
            "1119,1\n",
            "1120,1\n",
            "1121,1\n",
            "1122,0\n",
            "1123,0\n",
            "1124,1\n",
            "1125,1\n",
            "1126,1\n",
            "1127,0\n",
            "1128,0\n",
            "1129,0\n",
            "1130,0\n",
            "1131,0\n",
            "1132,0\n",
            "1133,1\n",
            "1134,1\n",
            "1135,1\n",
            "1136,0\n",
            "1137,1\n",
            "1138,0\n",
            "1139,1\n",
            "1140,0\n",
            "1141,0\n",
            "1142,1\n",
            "1143,0\n",
            "1144,1\n",
            "1145,0\n",
            "1146,1\n",
            "1147,0\n",
            "1148,1\n",
            "1149,0\n",
            "1150,0\n",
            "1151,0\n",
            "1152,0\n",
            "1153,1\n",
            "1154,1\n",
            "1155,0\n",
            "1156,0\n",
            "1157,1\n",
            "1158,1\n",
            "1159,0\n",
            "1160,0\n",
            "1161,0\n",
            "1162,0\n",
            "1163,1\n",
            "1164,0\n",
            "1165,1\n",
            "1166,0\n",
            "1167,0\n",
            "1168,1\n",
            "1169,1\n",
            "1170,0\n",
            "1171,1\n",
            "1172,0\n",
            "1173,0\n",
            "1174,0\n",
            "1175,0\n",
            "1176,0\n",
            "1177,0\n",
            "1178,1\n",
            "1179,0\n",
            "1180,0\n",
            "1181,0\n",
            "1182,0\n",
            "1183,0\n",
            "1184,0\n",
            "1185,0\n",
            "1186,0\n",
            "1187,0\n",
            "1188,1\n",
            "1189,0\n",
            "1190,0\n",
            "1191,1\n",
            "1192,1\n",
            "1193,0\n",
            "1194,0\n",
            "1195,1\n",
            "1196,0\n",
            "1197,0\n",
            "1198,0\n",
            "1199,0\n",
            "1200,0\n",
            "1201,0\n",
            "1202,1\n",
            "1203,0\n",
            "1204,0\n",
            "1205,1\n",
            "1206,0\n",
            "1207,1\n",
            "1208,0\n",
            "1209,0\n",
            "1210,1\n",
            "1211,1\n",
            "1212,0\n",
            "1213,0\n",
            "1214,0\n",
            "1215,1\n",
            "1216,0\n",
            "1217,1\n",
            "1218,1\n",
            "1219,1\n",
            "1220,0\n",
            "1221,0\n",
            "1222,0\n",
            "1223,0\n",
            "1224,0\n",
            "1225,1\n",
            "1226,1\n",
            "1227,0\n",
            "1228,1\n",
            "1229,1\n",
            "1230,0\n",
            "1231,0\n",
            "1232,0\n",
            "1233,0\n",
            "1234,0\n",
            "1235,0\n",
            "1236,0\n",
            "1237,1\n",
            "1238,1\n",
            "1239,1\n",
            "1240,0\n",
            "1241,0\n",
            "1242,1\n",
            "1243,1\n",
            "1244,0\n",
            "1245,0\n",
            "1246,0\n",
            "1247,0\n",
            "1248,0\n",
            "1249,0\n",
            "1250,1\n",
            "1251,0\n",
            "1252,0\n",
            "1253,0\n",
            "1254,0\n",
            "1255,0\n",
            "1256,0\n",
            "1257,0\n",
            "1258,0\n",
            "1259,0\n",
            "1260,0\n",
            "1261,1\n",
            "1262,0\n",
            "1263,1\n",
            "1264,0\n",
            "1265,0\n",
            "1266,1\n",
            "1267,0\n",
            "1268,1\n",
            "1269,0\n",
            "1270,1\n",
            "1271,1\n",
            "1272,0\n",
            "1273,0\n",
            "1274,1\n",
            "1275,0\n",
            "1276,0\n",
            "1277,0\n",
            "1278,1\n",
            "1279,1\n",
            "1280,0\n",
            "1281,0\n",
            "1282,0\n",
            "1283,1\n",
            "1284,0\n",
            "1285,1\n",
            "1286,0\n",
            "1287,0\n",
            "1288,0\n",
            "1289,0\n",
            "1290,0\n",
            "1291,0\n",
            "1292,1\n",
            "1293,0\n",
            "1294,1\n",
            "1295,1\n",
            "1296,1\n",
            "1297,0\n",
            "1298,1\n",
            "1299,1\n",
            "1300,1\n",
            "1301,1\n",
            "1302,1\n",
            "1303,0\n",
            "1304,0\n",
            "1305,1\n",
            "1306,0\n",
            "1307,1\n",
            "1308,1\n",
            "1309,0\n",
            "1310,0\n",
            "1311,0\n",
            "1312,0\n",
            "1313,1\n",
            "1314,0\n",
            "1315,1\n",
            "1316,0\n",
            "1317,0\n",
            "1318,1\n",
            "1319,1\n",
            "1320,1\n",
            "1321,0\n",
            "1322,0\n",
            "1323,0\n",
            "1324,0\n",
            "1325,0\n",
            "1326,0\n",
            "1327,0\n",
            "1328,0\n",
            "1329,1\n",
            "1330,0\n",
            "1331,0\n",
            "1332,0\n",
            "1333,1\n",
            "1334,0\n",
            "1335,1\n",
            "1336,0\n",
            "1337,0\n",
            "1338,0\n",
            "1339,1\n",
            "1340,0\n",
            "1341,1\n",
            "1342,0\n",
            "1343,0\n",
            "1344,0\n",
            "1345,0\n",
            "1346,0\n",
            "1347,1\n",
            "1348,1\n",
            "1349,1\n",
            "1350,0\n",
            "1351,1\n",
            "1352,0\n",
            "1353,0\n",
            "1354,0\n",
            "1355,1\n",
            "1356,0\n",
            "1357,1\n",
            "1358,0\n",
            "1359,0\n",
            "1360,0\n",
            "1361,0\n",
            "1362,0\n",
            "1363,1\n",
            "1364,0\n",
            "1365,0\n",
            "1366,0\n",
            "1367,0\n",
            "1368,1\n",
            "1369,0\n",
            "1370,0\n",
            "1371,0\n",
            "1372,0\n",
            "1373,1\n",
            "1374,0\n",
            "1375,0\n",
            "1376,0\n",
            "1377,1\n",
            "1378,1\n",
            "1379,1\n",
            "1380,0\n",
            "1381,1\n",
            "1382,0\n",
            "1383,0\n",
            "1384,1\n",
            "1385,1\n",
            "1386,0\n",
            "1387,0\n",
            "1388,0\n",
            "1389,0\n",
            "1390,1\n",
            "1391,0\n",
            "1392,0\n",
            "1393,0\n",
            "1394,1\n",
            "1395,0\n",
            "1396,0\n",
            "1397,0\n",
            "1398,0\n",
            "1399,0\n",
            "1400,1\n",
            "1401,0\n",
            "1402,0\n",
            "1403,0\n",
            "1404,0\n",
            "1405,0\n",
            "1406,1\n",
            "1407,1\n",
            "1408,0\n",
            "1409,0\n",
            "1410,0\n",
            "1411,0\n",
            "1412,0\n",
            "1413,0\n",
            "1414,0\n",
            "1415,0\n",
            "1416,1\n",
            "1417,1\n",
            "1418,1\n",
            "1419,0\n",
            "1420,0\n",
            "1421,1\n",
            "1422,0\n",
            "1423,0\n",
            "1424,0\n",
            "1425,0\n",
            "1426,0\n",
            "1427,0\n",
            "1428,1\n",
            "1429,0\n",
            "1430,1\n",
            "1431,0\n",
            "1432,0\n",
            "1433,0\n",
            "1434,0\n",
            "1435,0\n",
            "1436,0\n",
            "1437,1\n",
            "1438,0\n",
            "1439,0\n",
            "1440,0\n",
            "1441,0\n",
            "1442,0\n",
            "1443,1\n",
            "1444,0\n",
            "1445,0\n",
            "1446,0\n",
            "1447,1\n",
            "1448,0\n",
            "1449,0\n",
            "1450,0\n",
            "1451,1\n",
            "1452,0\n",
            "1453,1\n",
            "1454,1\n",
            "1455,0\n",
            "1456,1\n",
            "1457,0\n",
            "1458,0\n",
            "1459,1\n",
            "1460,1\n",
            "1461,0\n",
            "1462,0\n",
            "1463,0\n",
            "1464,1\n",
            "1465,1\n",
            "1466,0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  '/content/bl_b_saved_weights3.pt' '/content/drive/MyDrive/Colab_Notebooks/NLP/best_add_rob_lstmandrob_model.pt'"
      ],
      "metadata": {
        "id": "VBNqQDZ-jTMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcQ6ufoHBEIV"
      },
      "source": [
        "**<h2> Tabla de Resultados </h2>**\n",
        "\n",
        "A continuación mostramos los resultados de la métrica de accuracy resumidos en una tabla para cada modelo.\n",
        "\n",
        "**No.** | **Model** | **Validation** | **Test**\n",
        " -------- |----|  ---- | ----\n",
        "1 |`Attention GRU` |  0.87563 | 0.80430\n",
        "2 | `Robertuito` |  0.90460 | 0.86987\n",
        "3 | `Robertuito_Gru` |  0.90460 | 0.88356\n",
        "4 | `Robertuito and Robertuito_Gru Voting Scheme`  | 0.90630 | 0.88827\n",
        "5 | `Add Robertuito and Robertuito_Gru Voting Scheme No Data Augmentation`  | 0.91141 | 0.88437\n",
        "6 | `Add Robertuito and Robertuito_Gru Voting Scheme Data Augmentation`  | 0.91482 | 0.89022\n",
        "6 | `Add Robertuito and Robertuito_LSTM Voting Scheme Data Augmentation`  | 0.90971 | 0.89247\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra"
      ],
      "metadata": {
        "id": "R9078hnUPlsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BL_B(nn.Module):\n",
        "  def __init__(self, attn_h_s, hidden_s, dense_hidden_s, bidir, n_lays):\n",
        "      super(BL_B, self).__init__()\n",
        "      '''\n",
        "      Input:\n",
        "          bert: pre-trained bert model\n",
        "      '''\n",
        "      model = AttnRNN(emb_mat=train_dataset.emb_matrix, \n",
        "                bidirectional=bidir, \n",
        "                num_layers=n_lays, \n",
        "                attn_hidden_size=attn_h_s, \n",
        "                hidden_size=hidden_s, \n",
        "                dense_hidden_size=dense_hidden_s\n",
        "                )\n",
        "\n",
        "\n",
        "      robertuito2_bl = AutoModelForSequenceClassification.from_pretrained(\"pysentimiento/robertuito-base-uncased\")\n",
        "\n",
        "      robertuito = AutoModelForSequenceClassification.from_pretrained(\"pysentimiento/robertuito-base-uncased\")\n",
        "\n",
        "      bl = BL(robertuito2_bl, model)\n",
        "\n",
        "      self.bl = bl # pretrained\n",
        "      self.model2  = RobertuitoClasificator(robertuito)\n",
        "      \n",
        "      \n",
        "  def forward(self, gruid, grulen, sent_id, mask):\n",
        "      # Get cls token\n",
        "      preds_m2 = self.model2(sent_id, mask)\n",
        "      preds_bl = self.bl(gruid, grulen, sent_id, mask)\n",
        "\n",
        "      lab1 = F.log_softmax(preds_m2, dim=1)\n",
        "      lab2 = F.log_softmax(preds_bl, dim=1)\n",
        "\n",
        "      lab2 = (lab1 + lab2)/2\n",
        "      \n",
        "      return lab2"
      ],
      "metadata": {
        "id": "LAxCMNgMPmuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class voting_sc(nn.Module):\n",
        "  def __init__(self, bl1, bl2):\n",
        "      super(voting_sc, self).__init__()\n",
        "      '''\n",
        "      Input:\n",
        "          bert: pre-trained bert model\n",
        "      '''\n",
        "      self.bl1 = bl1\n",
        "      self.bl2 = bl2\n",
        "      #self.bl3 = bl3\n",
        "\n",
        "      for param in self.bl1.parameters():\n",
        "        param.requires_grad = False\n",
        "      \n",
        "      for param in self.bl2.parameters():\n",
        "        param.requires_grad = False\n",
        "      \n",
        "      #for param in self.bl3.parameters():\n",
        "      #  param.requires_grad = False\n",
        "\n",
        "      self.yes_layer = nn.Linear(2, 1, bias=False)\n",
        "      self.no_layer = nn.Linear(2, 1, bias=False)\n",
        "      \n",
        "      \n",
        "  def forward(self, gruid, grulen, sent_id, mask):\n",
        "      # Get cls token\n",
        "      preds_bl1 = self.bl1(gruid, grulen, sent_id, mask)\n",
        "      preds_bl2 = self.bl1(gruid, grulen, sent_id, mask)\n",
        "      #preds_bl3 = self.bl1(gruid, grulen, sent_id, mask)\n",
        "      \n",
        "      yes = torch.concat([preds_bl1[:, 0:1], preds_bl2[:, 0:1]], dim=1)\n",
        "      yes = self.yes_layer(yes)\n",
        "\n",
        "      no = torch.concat([preds_bl1[:, 1:], preds_bl2[:, 1:]], dim=1)\n",
        "      no = self.no_layer(no)\n",
        "\n",
        "      out = torch.concat([yes, no], dim=1)\n",
        "      out = F.softmax(out, dim=1)\n",
        "\n",
        "      return out"
      ],
      "metadata": {
        "id": "zYj_vQnfLxqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}